{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4da54cf7",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4cd65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/bnnebedum/Flood-Mapping.git\n",
    "%cd Flood-Mapping\n",
    "!git log --oneline -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d028374",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt\n",
    "import sys\n",
    "sys.path.append('/content/Flood-Mapping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ca3f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"Running in Google Colab\")\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    import subprocess\n",
    "    import sys\n",
    "    \n",
    "    packages = [\"rasterio\", \"pyyaml\", \"tqdm\"]\n",
    "    for package in packages:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "    \n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "import sys\n",
    "if IN_COLAB:\n",
    "    project_paths = [\n",
    "        '/content/drive/MyDrive/Flood-Mapping',\n",
    "        '/content/Flood-Mapping',\n",
    "        '/content/drive/MyDrive/Flood-Mapping/src'\n",
    "    ]\n",
    "    \n",
    "    for path in project_paths:\n",
    "        if os.path.exists(path):\n",
    "            sys.path.append(path)\n",
    "            print(f\"Added to path: {path}\")\n",
    "            break\n",
    "    else:\n",
    "        print(\"Project not found in expected locations. Please upload the project to your Drive.\")\n",
    "        print(\"Expected location: /content/drive/MyDrive/Flood-Mapping/\")\n",
    "\n",
    "try:\n",
    "    from src.utils.config import ConfigManager, ExperimentConfig, get_default_config\n",
    "    from src.utils.colab_utils import setup_colab_environment\n",
    "    from src.training.trainer import FloodSegmentationTrainer\n",
    "    from src.evaluation.visualizer import FloodSegmentationVisualizer\n",
    "    print(\"[SUCCESS] All project modules imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"Import error: {e}\")\n",
    "    print(\"Please ensure the project structure is uploaded to your Google Drive\")\n",
    "    print(\"Required structure: /content/drive/MyDrive/Flood-Mapping/src/...\")\n",
    "    raise\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")\n",
    "\n",
    "from src.utils.data_validation import DataStructureValidator, quick_data_check\n",
    "\n",
    "# Quick check\n",
    "data_ready = quick_data_check()\n",
    "\n",
    "if not data_ready:\n",
    "    validator = DataStructureValidator()\n",
    "    validator.print_validation_report()\n",
    "    \n",
    "    raise ValueError(\"Data structure validation failed. Please check the issues above.\")\n",
    "\n",
    "setup_result = setup_colab_environment()\n",
    "\n",
    "data_verification = setup_result['data_verification']\n",
    "total_pairs = 0\n",
    "for split, info in data_verification['splits'].items():\n",
    "    pairs = info['matched_pairs']\n",
    "    total_pairs += pairs\n",
    "    print(f\"{split}: {pairs} matched pairs\")\n",
    "\n",
    "print(f\"Total dataset: {total_pairs} matched pairs\")\n",
    "\n",
    "if setup_result['metadata']:\n",
    "    if 'channel_analysis' in setup_result['metadata']:\n",
    "        channel_analysis = setup_result['metadata']['channel_analysis']\n",
    "        for channel, stats in channel_analysis.items():\n",
    "            print(f\"{channel}: contrast={stats['avg_contrast']:.3f}, separability={stats['avg_separability']:.3f}\")\n",
    "    \n",
    "    if 'normalization_stats' in setup_result['metadata']:\n",
    "        norm_stats = setup_result['metadata']['normalization_stats']\n",
    "        print(\"Channel means:\", [f\"{m:.1f}\" for m in norm_stats['mean']])\n",
    "        print(\"Channel stds:\", [f\"{s:.1f}\" for s in norm_stats['std']])\n",
    "else:\n",
    "    print(\"WARNING: No preprocessing metadata found. Using default normalization.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7aea80",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714b7949",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_paths = [\n",
    "    \"/content/drive/MyDrive/Flood-Mapping/configs/unet_config.yaml\",\n",
    "    \"/content/Flood-Mapping/configs/unet_config.yaml\"\n",
    "]\n",
    "\n",
    "config = None\n",
    "for config_path in config_paths:\n",
    "    if os.path.exists(config_path):\n",
    "        config = ConfigManager.load_config(config_path)\n",
    "        print(f\"Configuration loaded from: {config_path}\")\n",
    "        break\n",
    "\n",
    "if config is None:\n",
    "    print(\"Configuration file not found. Creating default configuration...\")\n",
    "    # Create default configuration\n",
    "    config = get_default_config(\"unet\")\n",
    "    \n",
    "    # Ensure the drive path matches your structure\n",
    "    config.data.drive_path = \"/content/drive/MyDrive/Preprocessed-128\"\n",
    "    config.output_dir = \"/content/drive/MyDrive/experiments\"\n",
    "    \n",
    "    print(\"Using default configuration\")\n",
    "\n",
    "config.data.drive_path = \"/content/drive/MyDrive/Preprocessed-128\"\n",
    "config.output_dir = \"/content/drive/MyDrive/experiments\"\n",
    "\n",
    "print(\"\\nCONFIGURATION SUMMARY\")\n",
    "print(f\"Experiment: {config.experiment_name}\")\n",
    "print(f\"Model: {config.model.name}\")\n",
    "print(f\"Batch size: {config.data.batch_size}\")\n",
    "print(f\"Epochs: {config.training.epochs}\")\n",
    "print(f\"Learning rate: {config.training.initial_lr}\")\n",
    "print(f\"Data path: {config.data.drive_path}\")\n",
    "print(f\"Output path: {config.output_dir}\")\n",
    "\n",
    "if not os.path.exists(config.data.drive_path):\n",
    "    raise FileNotFoundError(f\"Data path not found: {config.data.drive_path}\")\n",
    "print(f\"Data path verified: {config.data.drive_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8f45d5",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8e0e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = FloodSegmentationTrainer(config)\n",
    "\n",
    "trainer.setup_datasets()\n",
    "\n",
    "trainer.setup_model()\n",
    "\n",
    "print(f\"\\nModel has {trainer.model.count_params():,} parameters\")\n",
    "\n",
    "print(\"If you see this it means you have the most recent commit\")\n",
    "training_history = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1b1b39",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de56e695",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = trainer.evaluate_test_set()\n",
    "\n",
    "for metric, value in test_results.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50c80d6",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1592c62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = FloodSegmentationVisualizer(config.evaluation)\n",
    "\n",
    "viz_results = visualizer.generate_sample_visualizations(\n",
    "    model=trainer.model,\n",
    "    dataset=trainer.test_dataset,\n",
    "    output_dir=trainer.experiment_dir,\n",
    "    num_samples=20\n",
    ")\n",
    "\n",
    "print(f\"Generated {viz_results['num_samples']} visualizations\")\n",
    "print(f\"Saved to: {viz_results['output_directory']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf2c82c",
   "metadata": {},
   "source": [
    "## Analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58ccceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_file = trainer.experiment_dir / 'training_history.json'\n",
    "with open(history_file, 'r') as f:\n",
    "    history_data = json.load(f)\n",
    "\n",
    "final_metrics = history_data['final_metrics']\n",
    "\n",
    "print(\"Final Training Metrics:\")\n",
    "print(f\"  Train Loss: {final_metrics['train_loss']:.4f}\")\n",
    "print(f\"  Val Loss: {final_metrics['val_loss']:.4f}\")\n",
    "print(f\"  Train DICE: {final_metrics['train_dice_coefficient']:.4f}\")\n",
    "print(f\"  Val DICE: {final_metrics['val_dice_coefficient']:.4f}\")\n",
    "print(f\"  Train Pixel Accuracy: {final_metrics['train_pixel_accuracy']:.4f}\")\n",
    "print(f\"  Val Pixel Accuracy: {final_metrics['val_pixel_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32be2594",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060ad940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history_data):\n",
    "    history = history_data['history']\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Loss\n",
    "    axes[0, 0].plot(history['loss'], label='Training Loss')\n",
    "    axes[0, 0].plot(history['val_loss'], label='Validation Loss')\n",
    "    axes[0, 0].set_title('Model Loss')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # DICE Coefficient\n",
    "    axes[0, 1].plot(history['dice_coefficient'], label='Training DICE')\n",
    "    axes[0, 1].plot(history['val_dice_coefficient'], label='Validation DICE')\n",
    "    axes[0, 1].set_title('DICE Coefficient')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('DICE')\n",
    "    axes[0, 1].legend()\n",
    "    \n",
    "    # Precision\n",
    "    axes[1, 0].plot(history['precision'], label='Training Precision')\n",
    "    axes[1, 0].plot(history['val_precision'], label='Validation Precision')\n",
    "    axes[1, 0].set_title('Precision')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Precision')\n",
    "    axes[1, 0].legend()\n",
    "    \n",
    "    # Recall\n",
    "    axes[1, 1].plot(history['recall'], label='Training Recall')\n",
    "    axes[1, 1].plot(history['val_recall'], label='Validation Recall')\n",
    "    axes[1, 1].set_title('Recall')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Recall')\n",
    "    axes[1, 1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plot_path = trainer.experiment_dir / 'training_history_plot.png'\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Training history plot saved to: {plot_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052c51e2",
   "metadata": {},
   "source": [
    "## Save and summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b86a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(config.training.save_weights_only)\n",
    "\n",
    "print(f\"\\nExperiment completed successfully!\")\n",
    "print(f\"Results saved to: {trainer.experiment_dir}\")\n",
    "print(f\"Experiment summary: {trainer.experiment_dir / 'experiment_summary.json'}\")\n",
    "\n",
    "print(\"EXPERIMENT SUMMARY\")\n",
    "print(f\"Experiment Name: {config.experiment_name}\")\n",
    "print(f\"Model: {config.model.name}\")\n",
    "print(f\"Dataset Size:\")\n",
    "for split, info in data_verification['splits'].items():\n",
    "    print(f\"  {split}: {info['matched_pairs']} pairs\")\n",
    "print(f\"\\nFinal Test Results:\")\n",
    "for metric, value in test_results.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {metric}: {value:.4f}\")\n",
    "print(f\"\\nTraining Time: {history_data.get('training_time_seconds', 0)/60:.1f} minutes\")\n",
    "print(f\"Total Parameters: {trainer.model.count_params():,}\")\n",
    "print(f\"Results Directory: {trainer.experiment_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "floodenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
